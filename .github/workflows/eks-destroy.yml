name: EKS Destroy Pipeline

on:
  workflow_dispatch: # Manual trigger only
    inputs:
      confirm_destroy:
        description: 'Type DESTROY to confirm'
        required: true
        default: 'NO'

env:
  AWS_REGION: us-east-1

jobs:
  destroy-applications:
    name: Destroy Applications
    runs-on: ubuntu-latest
    if: github.event.inputs.confirm_destroy == 'DESTROY'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: 'latest'

      - name: Setup Helm
        uses: azure/setup-helm@v3
        with:
          version: 'v3.8.0'

      - name: Get EKS credentials
        run: |
          echo "Getting EKS cluster credentials..."
          aws eks update-kubeconfig --name my-eks-cluster --region us-east-1

      - name: Destroy Applications
        run: |
          echo "=== DESTROYING APPLICATIONS ==="
          
          # Uninstall application
          if helm list | grep -q myapp; then
            echo "Uninstalling myapp..."
            helm uninstall myapp --wait
          else
            echo "myapp not found"
          fi
          
          # Uninstall database
          if helm list | grep -q postgres; then
            echo "Uninstalling postgres..."
            helm uninstall postgres --wait
          else
            echo "postgres not found"
          fi
          
          # Uninstall CSI Secrets Store
          if helm list -n kube-system | grep -q csi-secrets-store; then
            echo "Uninstalling CSI Secrets Store..."
            helm uninstall csi-secrets-store -n kube-system --wait
          else
            echo "CSI Secrets Store not found"
          fi
          
          echo "‚úÖ Applications destroyed"

      - name: Clean up Kubernetes resources
        run: |
          echo "=== CLEANING UP KUBERNETES RESOURCES ==="
          
          # Delete secrets
          kubectl delete secret db-credentials --ignore-not-found=true
          kubectl delete secret aws-ecr-secret --ignore-not-found=true
          
          # Delete service accounts
          kubectl delete serviceaccount myapp-sa --ignore-not-found=true
          
          # Delete SecretProviderClass
          kubectl delete secretproviderclass --all --ignore-not-found=true
          
          # Delete AWS provider
          kubectl delete -f https://raw.githubusercontent.com/aws/secrets-store-csi-driver-provider-aws/main/deployment/aws-provider-installer.yaml --ignore-not-found=true
          
          echo "‚úÖ Kubernetes resources cleaned up"

  destroy-infrastructure:
    name: Destroy Infrastructure
    needs: destroy-applications
    runs-on: ubuntu-latest
    if: github.event.inputs.confirm_destroy == 'DESTROY'
    defaults:
      run:
        working-directory: ./eks/terraform
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.0.0

      - name: Terraform Init
        run: terraform init -upgrade

      - name: Manual Resource Cleanup
        run: |
          echo "=== MANUAL RESOURCE CLEANUP ==="
          
          # Delete Load Balancers (created by Kubernetes services)
          echo "Checking for Load Balancers..."
          aws elbv2 describe-load-balancers --query 'LoadBalancers[?contains(LoadBalancerName, `k8s`) || contains(Tags[?Key==`kubernetes.io/cluster/my-eks-cluster`].Value, `owned`)].LoadBalancerArn' --output text | while read lb_arn; do
            if [ -n "$lb_arn" ]; then
              echo "Deleting Load Balancer: $lb_arn"
              aws elbv2 delete-load-balancer --load-balancer-arn $lb_arn || echo "Failed to delete LB"
            fi
          done
          
          # Delete Security Groups created by EKS
          echo "Checking for EKS Security Groups..."
          aws ec2 describe-security-groups --filters "Name=tag:kubernetes.io/cluster/my-eks-cluster,Values=owned" --query 'SecurityGroups[].GroupId' --output text | while read sg_id; do
            if [ -n "$sg_id" ]; then
              echo "Deleting Security Group: $sg_id"
              aws ec2 delete-security-group --group-id $sg_id || echo "Failed to delete SG"
            fi
          done
          
          # Wait for resources to be deleted
          sleep 60

      - name: Terraform Destroy
        run: |
          echo "=== TERRAFORM DESTROY ==="
          
          # Destroy with auto-approve
          if ! terraform destroy -auto-approve 2>&1 | tee destroy_output.log; then
            echo "‚ùå Terraform destroy failed, checking for common issues..."
            
            if grep -q "DependencyViolation\|InvalidGroup.InUse\|resource has a dependent object" destroy_output.log; then
              echo "‚ö†Ô∏è Dependency issues found, retrying after cleanup..."
              sleep 120
              terraform destroy -auto-approve || echo "‚ùå Second destroy attempt failed"
            else
              echo "‚ùå Terraform destroy failed with other errors"
              cat destroy_output.log
              exit 1
            fi
          else
            echo "‚úÖ Terraform destroy completed successfully"
          fi

      - name: Verify Destruction
        run: |
          echo "=== VERIFYING DESTRUCTION ==="
          
          # Check if EKS cluster still exists
          if aws eks describe-cluster --name my-eks-cluster 2>/dev/null; then
            echo "‚ùå EKS cluster still exists"
          else
            echo "‚úÖ EKS cluster destroyed"
          fi
          
          # Check if RDS instance still exists
          if aws rds describe-db-instances --db-instance-identifier eks-postgres 2>/dev/null; then
            echo "‚ùå RDS instance still exists"
          else
            echo "‚úÖ RDS instance destroyed"
          fi
          
          # Check if ElastiCache still exists
          if aws elasticache describe-cache-clusters --cache-cluster-id eks-redis 2>/dev/null; then
            echo "‚ùå ElastiCache cluster still exists"
          else
            echo "‚úÖ ElastiCache cluster destroyed"
          fi
          
          # Check if ECR repository still exists
          if aws ecr describe-repositories --repository-names myapp 2>/dev/null; then
            echo "‚ùå ECR repository still exists"
          else
            echo "‚úÖ ECR repository destroyed"
          fi
          
          echo "üéâ Destruction verification completed"

  cleanup-confirmation:
    name: Cleanup Confirmation
    needs: [destroy-applications, destroy-infrastructure]
    runs-on: ubuntu-latest
    if: github.event.inputs.confirm_destroy == 'DESTROY'
    
    steps:
      - name: Final Cleanup Summary
        run: |
          echo "üéâ EKS DESTRUCTION COMPLETED"
          echo ""
          echo "‚úÖ Applications destroyed:"
          echo "   - myapp application"
          echo "   - PostgreSQL database"
          echo "   - CSI Secrets Store driver"
          echo ""
          echo "‚úÖ Infrastructure destroyed:"
          echo "   - EKS cluster"
          echo "   - RDS PostgreSQL instance"
          echo "   - ElastiCache Redis cluster"
          echo "   - ECR repository"
          echo "   - VPC and networking"
          echo "   - IAM roles and policies"
          echo "   - Secrets Manager secrets"
          echo ""
          echo "‚ö†Ô∏è  Manual cleanup may be required for:"
          echo "   - Orphaned Load Balancers"
          echo "   - Orphaned Security Groups"
          echo "   - CloudWatch Log Groups"
          echo ""
          echo "üí∞ All billable resources have been destroyed"