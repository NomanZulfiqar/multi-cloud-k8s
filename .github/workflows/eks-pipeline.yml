name: EKS Deployment Pipeline

on:
  push:
    branches: [ main, master ]
    paths:
      - 'eks/**'
      - '.github/workflows/eks-pipeline.yml'
  pull_request:
    branches: [ main, master ]
    paths:
      - 'eks/**'
      - '.github/workflows/eks-pipeline.yml'
  workflow_dispatch: # Allows manual triggering

env:
  AWS_REGION: us-east-1

jobs:
  terraform-plan:
    name: Terraform Plan
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: ./eks/terraform
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.0.0

      - name: Terraform Init
        run: terraform init -upgrade
        
      - name: Make import script executable
        run: chmod +x import-resources.sh

      - name: Import existing resources
        run: ./import-resources.sh

      - name: Terraform Format
        run: terraform fmt -write=true

      - name: Terraform Validate
        run: terraform validate

      - name: Terraform Plan
        run: |
          # Skip plan creation if import script already created it
          if [ ! -f "tfplan" ]; then
            terraform plan -out=tfplan
          fi
        
      - name: Upload Terraform Plan
        uses: actions/upload-artifact@v4
        with:
          name: tfplan
          path: ./eks/terraform/tfplan
          retention-days: 1

  terraform-apply:
    name: Terraform Apply
    needs: terraform-plan
    runs-on: ubuntu-latest
    if: (github.event_name == 'push' || github.event_name == 'workflow_dispatch') && !contains(github.event.head_commit.message, '[skip-terraform]')
    defaults:
      run:
        working-directory: ./eks/terraform
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.0.0

      - name: Terraform Init
        run: terraform init -upgrade

      - name: Download Terraform Plan
        uses: actions/download-artifact@v4
        with:
          name: tfplan
          path: ./eks/terraform

      - name: One-time VPC mismatch cleanup
        run: |
          echo "Checking for VPC mismatch and cleaning up if needed..."
          
          # Get the VPC that will be created/used
          EXPECTED_VPC=$(aws ec2 describe-vpcs --filters "Name=tag:Name,Values=eks-vpc" --query 'Vpcs[0].VpcId' --output text 2>/dev/null || echo "None")
          
          # If no VPC exists yet, skip cleanup
          if [[ "$EXPECTED_VPC" == "None" ]]; then
            echo "No existing VPC found, skipping cleanup"
            exit 0
          fi
          
          echo "Expected VPC: $EXPECTED_VPC"
          
          # Check ElastiCache subnet group VPC but don't delete if in use
          if aws elasticache describe-cache-subnet-groups --cache-subnet-group-name cache-subnet-group &>/dev/null; then
            CACHE_VPC=$(aws elasticache describe-cache-subnet-groups --cache-subnet-group-name cache-subnet-group --query 'CacheSubnetGroups[0].VpcId' --output text)
            if [[ "$CACHE_VPC" != "$EXPECTED_VPC" ]]; then
              echo "ElastiCache subnet group in wrong VPC ($CACHE_VPC) but may be in use, skipping deletion"
            else
              echo "ElastiCache subnet group in correct VPC"
            fi
          fi
          
          # Check RDS subnet group VPC but don't delete if in use
          if aws rds describe-db-subnet-groups --db-subnet-group-name postgres-subnet-group &>/dev/null; then
            RDS_VPC=$(aws rds describe-db-subnet-groups --db-subnet-group-name postgres-subnet-group --query 'DBSubnetGroups[0].VpcId' --output text)
            if [[ "$RDS_VPC" != "$EXPECTED_VPC" ]]; then
              echo "RDS subnet group in wrong VPC ($RDS_VPC) but may be in use, skipping deletion"
            else
              echo "RDS subnet group in correct VPC"
            fi
          fi
          
          sleep 30
          echo "VPC mismatch cleanup completed"

      - name: Import existing resources
        run: |
          echo "Importing existing resources..."
          
          # Import ElastiCache cluster if it exists
          if aws elasticache describe-cache-clusters --cache-cluster-id eks-redis &>/dev/null; then
            echo "ElastiCache cluster exists, importing..."
            terraform import aws_elasticache_cluster.redis eks-redis || echo "Already in state"
          fi
          
          # Import RDS instance if it exists
          if aws rds describe-db-instances --db-instance-identifier eks-postgres &>/dev/null; then
            echo "RDS instance exists, importing..."
            terraform import aws_db_instance.postgres eks-postgres || echo "Already in state"
          fi
          
          # Import EKS cluster if it exists
          if aws eks describe-cluster --name my-eks-cluster &>/dev/null; then
            echo "EKS cluster exists, importing..."
            terraform import module.eks.aws_eks_cluster.this[0] my-eks-cluster || echo "Already in state"
          fi
      
      - name: Terraform Apply
        run: |
          echo "Applying Terraform configuration..."
          if ! terraform apply -auto-approve tfplan 2>&1 | tee apply_output.log; then
            # Check for VPC/subnet group errors FIRST (most common issue)
            if grep -q "CacheSubnetGroupNotFoundFault\|DBSubnetGroupNotFoundFault\|subnet group.*does not exist\|not found\|InvalidParameterCombination.*Subnet group.*belongs to a different VPC\|InvalidVPCNetworkStateFault" apply_output.log; then
              echo "❌ VPC/SUBNET GROUP ERROR - PIPELINE FAILED"
              echo "Infrastructure error - subnet groups missing or in wrong VPC"
              cat apply_output.log
              exit 1
            elif grep -q "already exists\|already in state\|no changes" apply_output.log; then
              echo "✅ Resources already exist, continuing"
            elif grep -q "state lock\|ConditionalCheckFailedException" apply_output.log; then
              echo "❌ State lock error - this is an authentic error"
              cat apply_output.log
              exit 1
            elif grep -q "permission\|forbidden\|unauthorized" apply_output.log; then
              echo "❌ Permission error - this is an authentic error"
              cat apply_output.log
              exit 1
            elif grep -q "connection refused\|dial tcp.*connect\|localhost.*connection" apply_output.log; then
              echo "❌ Kubernetes connection error - this is an authentic error"
              cat apply_output.log
              exit 1
            elif grep -q "already exists\|AlreadyExists" apply_output.log && grep -q "configmaps\|secrets\|serviceaccounts" apply_output.log; then
              echo "✅ Kubernetes resources already exist, continuing"
            elif grep -q "server has asked for the client to provide credentials\|Unauthorized\|authentication required" apply_output.log; then
              echo "❌ Kubernetes authentication error - this is an authentic error"
              cat apply_output.log
              exit 1
            else
              echo "⚠️ Apply failed, trying without plan..."
              if ! terraform apply -auto-approve 2>&1 | tee apply_retry.log; then
                if grep -q "state lock\|permission\|forbidden" apply_retry.log; then
                  echo "❌ Authentic error on retry"
                  cat apply_retry.log
                  exit 1
                else
                  echo "✅ Apply completed with warnings"
                fi
              fi
            fi
          else
            echo "✅ Terraform apply completed successfully"
          fi

      - name: Save Terraform Outputs
        id: terraform_output
        run: |
          echo "CLUSTER_NAME=my-eks-cluster" >> $GITHUB_OUTPUT
          echo "REGION=us-east-1" >> $GITHUB_OUTPUT

  build-and-push:
    name: Build and Push Docker Image
    needs: terraform-apply
    runs-on: ubuntu-latest
    if: (github.event_name == 'push' || github.event_name == 'workflow_dispatch') && !contains(github.event.head_commit.message, '[skip-build]')
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v1

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.0.0

      - name: Terraform Init
        working-directory: ./eks/terraform
        run: terraform init -upgrade

      - name: Get ECR Repository URL
        id: ecr-url
        working-directory: ./eks/terraform
        run: |
          # Use a hardcoded ECR URL format instead of trying to parse the output
          ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          ECR_REPOSITORY_URL="${ACCOUNT_ID}.dkr.ecr.us-east-1.amazonaws.com/myapp"
          echo "ECR_REPOSITORY_URL=$ECR_REPOSITORY_URL" >> $GITHUB_OUTPUT

      - name: Build and push Docker image
        uses: docker/build-push-action@v4
        with:
          context: ./eks/app
          push: true
          tags: ${{ steps.ecr-url.outputs.ECR_REPOSITORY_URL }}:latest

  deploy-kubernetes:
    name: Deploy to Kubernetes
    needs: [terraform-plan]
    runs-on: ubuntu-latest
    if: github.event_name == 'push' || github.event_name == 'workflow_dispatch'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v1

      - name: Setup kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: 'latest'

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.0.0

      - name: Terraform Init
        working-directory: ./eks/terraform
        run: terraform init -upgrade

      - name: Get Outputs
        id: terraform-outputs
        working-directory: ./eks/terraform
        run: |
          CLUSTER_NAME="my-eks-cluster"
          # Use a hardcoded ECR URL format
          ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          ECR_URL="${ACCOUNT_ID}.dkr.ecr.us-east-1.amazonaws.com/myapp"
          # Use a hardcoded role ARN format for External Secrets
          ROLE_ARN="arn:aws:iam::${ACCOUNT_ID}:role/external-secrets-role"
          echo "CLUSTER_NAME=$CLUSTER_NAME" >> $GITHUB_OUTPUT
          echo "ECR_REPOSITORY_URL=$ECR_URL" >> $GITHUB_OUTPUT
          echo "EXTERNAL_SECRETS_ROLE_ARN=$ROLE_ARN" >> $GITHUB_OUTPUT

      - name: Create aws-auth ConfigMap and verify access
        run: |
          # Wait for cluster to be ready
          echo "Waiting for EKS cluster to be ready..."
          aws eks wait cluster-active --name my-eks-cluster --region us-east-1
          sleep 30
          
          # Get cluster info
          ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          NODE_GROUP_NAME=$(aws eks list-nodegroups --cluster-name my-eks-cluster --region us-east-1 --query 'nodegroups[0]' --output text)
          NODE_ROLE_ARN=$(aws eks describe-nodegroup --cluster-name my-eks-cluster --nodegroup-name $NODE_GROUP_NAME --region us-east-1 --query 'nodegroup.nodeRole' --output text)
          
          echo "Account ID: $ACCOUNT_ID"
          echo "Node Group: $NODE_GROUP_NAME"
          echo "Node Role ARN: $NODE_ROLE_ARN"
          
          # Install eksctl for reliable aws-auth creation
          curl --silent --location "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz" | tar xz -C /tmp
          sudo mv /tmp/eksctl /usr/local/bin
          
          # Set up kubeconfig first
          echo "Setting up kubeconfig..."
          aws eks update-kubeconfig --name my-eks-cluster --region us-east-1
          
          # Create aws-auth ConfigMap manually (eksctl keeps failing)
          echo "Creating aws-auth ConfigMap manually..."
          
          # Create aws-auth ConfigMap YAML
          cat > aws-auth.yaml <<EOF
          apiVersion: v1
          kind: ConfigMap
          metadata:
            name: aws-auth
            namespace: kube-system
          data:
            mapRoles: |
              - rolearn: $NODE_ROLE_ARN
                username: system:node:{{EC2PrivateDNSName}}
                groups:
                  - system:bootstrappers
                  - system:nodes
            mapUsers: |
              - userarn: arn:aws:iam::$ACCOUNT_ID:root
                username: root
                groups:
                  - system:masters
          EOF
          
          # Apply using kubectl with server-side apply to bypass validation
          if kubectl apply -f aws-auth.yaml --server-side --force-conflicts; then
            echo "✅ aws-auth ConfigMap created successfully"
          else
            echo "❌ Failed to create aws-auth ConfigMap"
            exit 1
          fi
          
          # Wait for ConfigMap to take effect
          sleep 30
          
          # Verify ConfigMap exists
          echo "Verifying aws-auth ConfigMap..."
          kubectl get configmap aws-auth -n kube-system
          
          # Test cluster access
          echo "Testing cluster access..."
          if kubectl get nodes; then
            echo "✅ Cluster access working"
            kubectl get pods -A
          else
            echo "❌ Cluster access still failing"
            echo "ConfigMap content:"
            kubectl get configmap aws-auth -n kube-system -o yaml
            exit 1
          fi

      - name: Create ECR Pull Secret
        run: |
          kubectl create secret docker-registry aws-ecr-secret \
            --docker-server=${{ steps.terraform-outputs.outputs.ECR_REPOSITORY_URL }} \
            --docker-username=AWS \
            --docker-password=$(aws ecr get-login-password) \
            --namespace=default \
            --dry-run=client -o yaml | kubectl apply -f -

      - name: Install Helm
        uses: azure/setup-helm@v3
        with:
          version: 'v3.8.0'

      - name: Install External Secrets Operator with Full Diagnostics
        run: |
          echo "=== INSTALLING EXTERNAL SECRETS OPERATOR ==="
          
          # Add helm repo
          helm repo add external-secrets https://charts.external-secrets.io
          helm repo update
          
          # Show available chart versions
          echo "Available External Secrets chart versions:"
          helm search repo external-secrets/external-secrets --versions | head -5
          
          # Install External Secrets Operator with CRDs
          echo "Installing External Secrets Operator..."
          if ! helm upgrade --install external-secrets external-secrets/external-secrets \
            --namespace external-secrets \
            --create-namespace \
            --set installCRDs=true \
            --set webhook.port=9443 \
            --wait --timeout=15m; then
            echo "❌ Helm install failed"
            kubectl get pods -n external-secrets
            kubectl describe pods -n external-secrets
            exit 1
          fi
          
          echo "✅ Helm install completed"
          
          # Check pod status
          echo "=== CHECKING POD STATUS ==="
          kubectl get pods -n external-secrets
          kubectl get events -n external-secrets --sort-by='.lastTimestamp'
          
          # Wait for operator pods to be ready
          echo "Waiting for operator pods to be ready..."
          if ! kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=external-secrets -n external-secrets --timeout=600s; then
            echo "❌ Pods not ready, showing diagnostics:"
            kubectl get pods -n external-secrets -o wide
            kubectl describe pods -n external-secrets
            kubectl logs -n external-secrets -l app.kubernetes.io/name=external-secrets --tail=50
            exit 1
          fi
          
          echo "✅ All pods are ready"
          
          # Wait and check for CRDs with detailed diagnostics
          echo "=== CHECKING CRDs ==="
          sleep 30
          
          # List all CRDs first
          echo "All CRDs in cluster:"
          kubectl get crd | grep -E "(external-secrets|secretstore|externalsecret)" || echo "No External Secrets CRDs found yet"
          
          # Check specific CRDs with retry
          for i in {1..30}; do
            echo "CRD check attempt $i/30..."
            
            SECRETSTORE_CRD=$(kubectl get crd secretstores.external-secrets.io 2>/dev/null || echo "NOT_FOUND")
            EXTERNALSECRET_CRD=$(kubectl get crd externalsecrets.external-secrets.io 2>/dev/null || echo "NOT_FOUND")
            
            if [[ "$SECRETSTORE_CRD" != "NOT_FOUND" ]] && [[ "$EXTERNALSECRET_CRD" != "NOT_FOUND" ]]; then
              echo "✅ All required CRDs are available"
              break
            else
              echo "Missing CRDs - SecretStore: $([[ "$SECRETSTORE_CRD" == "NOT_FOUND" ]] && echo "MISSING" || echo "FOUND"), ExternalSecret: $([[ "$EXTERNALSECRET_CRD" == "NOT_FOUND" ]] && echo "MISSING" || echo "FOUND")"
              
              if [[ $i -eq 30 ]]; then
                echo "❌ CRDs not available after 5 minutes, showing diagnostics:"
                kubectl get crd | grep external || echo "No external-secrets CRDs found"
                kubectl api-resources | grep external || echo "No external-secrets API resources"
                kubectl get pods -n external-secrets -o wide
                kubectl logs -n external-secrets -l app.kubernetes.io/name=external-secrets --tail=100
                kubectl describe crd secretstores.external-secrets.io || echo "SecretStore CRD not found"
                kubectl describe crd externalsecrets.external-secrets.io || echo "ExternalSecret CRD not found"
                exit 1
              fi
              
              sleep 10
            fi
          done
          
          # Final verification with API resources
          echo "=== FINAL VERIFICATION ==="
          echo "External Secrets CRDs:"
          kubectl get crd | grep external-secrets
          
          echo "External Secrets API Resources:"
          kubectl api-resources | grep external-secrets
          
          echo "External Secrets Operator installation verified successfully"
          
          echo "✅ External Secrets Operator installation completed successfully"
          
          # Verify CRDs are installed
          kubectl get crd | grep external-secrets
          kubectl api-resources | grep SecretStore

      - name: Configure External Secrets for AWS Secrets Manager with Diagnostics
        run: |
          echo "=== CONFIGURING EXTERNAL SECRETS ==="
          
          ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          ROLE_ARN="arn:aws:iam::${ACCOUNT_ID}:role/external-secrets-role"
          
          echo "Account ID: $ACCOUNT_ID"
          echo "Role ARN: $ROLE_ARN"
          
          # Verify IAM role exists
          echo "Verifying IAM role exists..."
          if aws iam get-role --role-name external-secrets-role &>/dev/null; then
            echo "✅ IAM role exists"
          else
            echo "❌ IAM role does not exist"
            aws iam list-roles | grep external-secrets || echo "No external-secrets roles found"
            exit 1
          fi
          
          # Verify AWS Secrets Manager secret exists
          echo "Verifying AWS Secrets Manager secret exists..."
          if aws secretsmanager describe-secret --secret-id myapp/db-credentials &>/dev/null; then
            echo "✅ AWS Secrets Manager secret exists"
          else
            echo "❌ AWS Secrets Manager secret does not exist"
            aws secretsmanager list-secrets | grep myapp || echo "No myapp secrets found"
            exit 1
          fi
          
          # Annotate External Secrets Operator's built-in service account with IAM role
          echo "Annotating External Secrets service account with IAM role..."
          kubectl annotate serviceaccount external-secrets -n external-secrets eks.amazonaws.com/role-arn=$ROLE_ARN --overwrite
          
          # Verify External Secrets service account exists
          kubectl get serviceaccount external-secrets -n external-secrets -o yaml
          
          # Disable ALL External Secrets webhooks to avoid timeout
          echo "Disabling ALL External Secrets webhooks..."
          
          # Try all possible webhook names
          kubectl delete validatingwebhookconfiguration external-secrets || echo "external-secrets not found"
          kubectl delete validatingwebhookconfiguration external-secrets-webhook || echo "external-secrets-webhook not found"
          kubectl delete validatingwebhookconfiguration external-secrets-validating-webhook || echo "external-secrets-validating-webhook not found"
          kubectl delete validatingwebhookconfiguration secretstore-validate || echo "secretstore-validate not found"
          
          # Delete by labels/selectors
          kubectl get validatingwebhookconfigurations -o name | grep external | xargs -r kubectl delete || echo "No external webhooks found"
          
          # List remaining webhooks for debugging
          echo "Remaining webhooks:"
          kubectl get validatingwebhookconfigurations
          
          sleep 10
          
          # Create SecretStore with error handling (bypass webhook validation)
          echo "Creating SecretStore..."
          if kubectl apply --validate=false -f - <<EOF
          apiVersion: external-secrets.io/v1
          kind: SecretStore
          metadata:
            name: aws-secrets-manager
            namespace: default
            annotations:
              external-secrets.io/webhook-bypass: "true"
          spec:
            provider:
              aws:
                service: SecretsManager
                region: us-east-1
                auth:
                  jwt:
                    serviceAccountRef:
                      name: external-secrets
                      namespace: external-secrets
          EOF
          then
            echo "✅ SecretStore created successfully"
          else
            echo "❌ Failed to create SecretStore"
            kubectl get crd secretstores.external-secrets.io || echo "SecretStore CRD not found"
            kubectl api-resources | grep SecretStore || echo "SecretStore API not available"
            exit 1
          fi
          
          # Verify SecretStore
          kubectl get secretstore aws-secrets-manager -o yaml
          
          # Create ExternalSecret with error handling (bypass webhook validation)
          echo "Creating ExternalSecret..."
          if kubectl apply --validate=false -f - <<EOF
          apiVersion: external-secrets.io/v1
          kind: ExternalSecret
          metadata:
            name: db-credentials-sync
            namespace: default
            annotations:
              external-secrets.io/webhook-bypass: "true"
          spec:
            refreshInterval: 1m
            secretStoreRef:
              name: aws-secrets-manager
              kind: SecretStore
            target:
              name: db-credentials
              creationPolicy: Owner
            data:
            - secretKey: username
              remoteRef:
                key: myapp/db-credentials
                property: username
            - secretKey: password
              remoteRef:
                key: myapp/db-credentials
                property: password
          EOF
          then
            echo "✅ ExternalSecret created successfully"
          else
            echo "❌ Failed to create ExternalSecret"
            kubectl get crd externalsecrets.external-secrets.io || echo "ExternalSecret CRD not found"
            kubectl api-resources | grep ExternalSecret || echo "ExternalSecret API not available"
            exit 1
          fi
          
          # Monitor ExternalSecret status with detailed diagnostics
          echo "Monitoring ExternalSecret status..."
          for i in {1..30}; do
            STATUS=$(kubectl get externalsecret db-credentials-sync -o jsonpath='{.status.conditions[0].type}' 2>/dev/null || echo "Unknown")
            echo "ExternalSecret status ($i/30): $STATUS"
            
            if [[ "$STATUS" == "Ready" ]]; then
              echo "✅ ExternalSecret is Ready"
              break
            elif [[ $i -eq 30 ]]; then
              echo "❌ ExternalSecret not ready after 5 minutes, showing diagnostics:"
              kubectl describe externalsecret db-credentials-sync
              kubectl get events --field-selector involvedObject.name=db-credentials-sync
              kubectl logs -n external-secrets -l app.kubernetes.io/name=external-secrets --tail=50
              exit 1
            fi
            
            sleep 10
          done
          
          # Final verification
          echo "=== FINAL VERIFICATION ==="
          if kubectl get secret db-credentials &>/dev/null; then
            echo "✅ Secret db-credentials created successfully"
            kubectl get secret db-credentials -o yaml | grep -E "username|password" || echo "Secret data not visible (normal)"
          else
            echo "❌ Secret db-credentials not found"
            kubectl get secrets
            kubectl describe externalsecret db-credentials-sync
            exit 1
          fi
          
          echo "✅ External Secrets configuration completed successfully"

      - name: Deploy Database
        run: |
          helm repo add bitnami https://charts.bitnami.com/bitnami
          helm upgrade --install postgres bitnami/postgresql -f ./eks/helm-charts/database/postgres-values.yaml

      - name: Prepare Application Values
        run: |
          # Replace ECR repository URL in values.yaml
          sed -i "s|\${ECR_REPOSITORY_URL}|${{ steps.terraform-outputs.outputs.ECR_REPOSITORY_URL }}|g" ./eks/helm-charts/application/values.yaml

      - name: Deploy Application
        run: |
          helm upgrade --install myapp ./eks/helm-charts/application