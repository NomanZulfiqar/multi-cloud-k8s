name: EKS Destruction Pipeline

on:
  workflow_dispatch:  # Manual trigger only

env:
  AWS_REGION: us-east-1

jobs:
  terraform-destroy:
    name: Terraform Destroy
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: ./eks/terraform
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.0.0

      - name: Terraform Init
        run: terraform init -upgrade

      - name: Setup kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: 'latest'

      - name: Install Helm
        uses: azure/setup-helm@v3
        with:
          version: 'v3.8.0'
          
      - name: Clean up Kubernetes resources
        run: |
          # Update kubeconfig (may fail if cluster doesn't exist)
          aws eks update-kubeconfig --name my-eks-cluster --region ${{ env.AWS_REGION }} || echo "Cluster may not exist, continuing"
          
          # Only proceed if cluster exists
          if kubectl cluster-info &>/dev/null; then
            echo "Cluster accessible, cleaning up resources..."
            
            # Delete Helm releases
            echo "Deleting Helm releases..."
            helm ls -A -q | xargs -r helm uninstall || echo "No Helm releases to delete"
            
            # Delete external-secrets namespace with timeout
            echo "Deleting external-secrets namespace..."
            kubectl delete namespace external-secrets --ignore-not-found=true --timeout=60s || echo "Namespace deletion timed out, continuing"
            
            # Delete any other application resources with timeout
            echo "Deleting application resources..."
            timeout 60s kubectl delete all --all -n default || echo "Resource deletion timed out or no resources to delete"
            
            echo "Kubernetes cleanup completed"
          else
            echo "Cluster not accessible, skipping Kubernetes cleanup"
          fi

      - name: Get EKS Resources
        id: get-resources
        run: |
          # Get node group name
          NODE_GROUP=$(aws eks list-nodegroups --cluster-name my-eks-cluster --query 'nodegroups[0]' --output text || echo "")
          echo "NODE_GROUP=$NODE_GROUP" >> $GITHUB_OUTPUT
          
          # Get ElastiCache cluster ID
          CACHE_CLUSTER=$(aws elasticache describe-cache-clusters --query 'CacheClusters[?CacheClusterId==`eks-redis`].CacheClusterId' --output text || echo "")
          echo "CACHE_CLUSTER=$CACHE_CLUSTER" >> $GITHUB_OUTPUT
          
          # Get RDS instance ID
          DB_INSTANCE=$(aws rds describe-db-instances --query 'DBInstances[?DBInstanceIdentifier==`eks-postgres`].DBInstanceIdentifier' --output text || echo "")
          echo "DB_INSTANCE=$DB_INSTANCE" >> $GITHUB_OUTPUT
          
          # Get ECR repository name
          ECR_REPO=$(aws ecr describe-repositories --query 'repositories[?repositoryName==`myapp`].repositoryName' --output text || echo "")
          echo "ECR_REPO=$ECR_REPO" >> $GITHUB_OUTPUT

      - name: Delete EKS Node Groups
        if: steps.get-resources.outputs.NODE_GROUP != ''
        run: |
          echo "Deleting node group: ${{ steps.get-resources.outputs.NODE_GROUP }}"
          aws eks delete-nodegroup --cluster-name my-eks-cluster --nodegroup-name ${{ steps.get-resources.outputs.NODE_GROUP }}
          
          # Wait for node group deletion (up to 10 minutes)
          for i in {1..20}; do
            STATUS=$(aws eks describe-nodegroup --cluster-name my-eks-cluster --nodegroup-name ${{ steps.get-resources.outputs.NODE_GROUP }} --query 'nodegroup.status' --output text 2>/dev/null || echo "DELETED")
            echo "Node group status: $STATUS"
            if [ "$STATUS" == "DELETED" ]; then
              break
            fi
            sleep 30
          done

      - name: Delete ElastiCache Cluster
        if: steps.get-resources.outputs.CACHE_CLUSTER != ''
        run: |
          echo "Deleting ElastiCache cluster: ${{ steps.get-resources.outputs.CACHE_CLUSTER }}"
          aws elasticache delete-cache-cluster --cache-cluster-id ${{ steps.get-resources.outputs.CACHE_CLUSTER }}
          
          # Wait for ElastiCache deletion (up to 10 minutes)
          for i in {1..20}; do
            STATUS=$(aws elasticache describe-cache-clusters --cache-cluster-id ${{ steps.get-resources.outputs.CACHE_CLUSTER }} --query 'CacheClusters[0].CacheClusterStatus' --output text 2>/dev/null || echo "DELETED")
            echo "ElastiCache status: $STATUS"
            if [ "$STATUS" == "DELETED" ]; then
              break
            fi
            sleep 30
          done

      - name: Delete RDS Instance
        if: steps.get-resources.outputs.DB_INSTANCE != ''
        run: |
          echo "Deleting RDS instance: ${{ steps.get-resources.outputs.DB_INSTANCE }}"
          aws rds delete-db-instance --db-instance-identifier ${{ steps.get-resources.outputs.DB_INSTANCE }} --skip-final-snapshot
          
          # Wait for RDS deletion (up to 15 minutes)
          for i in {1..30}; do
            STATUS=$(aws rds describe-db-instances --db-instance-identifier ${{ steps.get-resources.outputs.DB_INSTANCE }} --query 'DBInstances[0].DBInstanceStatus' --output text 2>/dev/null || echo "DELETED")
            echo "RDS status: $STATUS"
            if [ "$STATUS" == "DELETED" ]; then
              break
            fi
            sleep 30
          done
          
      - name: Delete AWS Secrets Manager Secret
        run: |
          echo "Deleting AWS Secrets Manager secret..."
          aws secretsmanager delete-secret --secret-id myapp/db-credentials --force-delete-without-recovery --region ${{ env.AWS_REGION }} || echo "Secret may not exist, continuing"

      - name: Clean up ECR Repository
        if: steps.get-resources.outputs.ECR_REPO != ''
        run: |
          echo "Cleaning up ECR repository: ${{ steps.get-resources.outputs.ECR_REPO }}"
          
          # Delete all images in the repository
          # First get the image digests
          DIGESTS=$(aws ecr list-images --repository-name ${{ steps.get-resources.outputs.ECR_REPO }} --query 'imageIds[*].imageDigest' --output text || echo "")
          
          if [ -n "$DIGESTS" ]; then
            echo "Deleting images from ECR repository..."
            for DIGEST in $DIGESTS; do
              echo "Deleting image with digest: $DIGEST"
              aws ecr batch-delete-image --repository-name ${{ steps.get-resources.outputs.ECR_REPO }} --image-ids imageDigest=$DIGEST || echo "Failed to delete image, continuing"
            done
          else
            echo "No images found in repository"
          fi
          
          # Note: We don't delete the ECR repository here as Terraform will handle it

      - name: Remove missing resources from state
        run: |
          # Remove resources that don't exist from Terraform state
          echo "Checking and removing missing resources from state..."
          
          # Check and remove Secrets Manager secret if it doesn't exist
          if ! aws secretsmanager describe-secret --secret-id myapp/db-credentials --region us-east-1 &>/dev/null; then
            echo "Secrets Manager secret not found, removing from state"
            terraform state rm aws_secretsmanager_secret.db_credentials || echo "Not in state"
          fi
          
          # Check and remove ElastiCache cluster if it doesn't exist
          if ! aws elasticache describe-cache-clusters --cache-cluster-id eks-redis &>/dev/null; then
            echo "ElastiCache cluster not found, removing from state"
            terraform state rm aws_elasticache_cluster.redis || echo "Not in state"
            terraform state rm aws_elasticache_subnet_group.cache_subnet_group || echo "Not in state"
          fi
          
          # Check and remove RDS instance if it doesn't exist
          if ! aws rds describe-db-instances --db-instance-identifier eks-postgres &>/dev/null; then
            echo "RDS instance not found, removing from state"
            terraform state rm aws_db_instance.postgres || echo "Not in state"
            terraform state rm aws_db_subnet_group.postgres || echo "Not in state"
          fi
          
          # Check and remove ECR repository if it doesn't exist
          if ! aws ecr describe-repositories --repository-names myapp &>/dev/null; then
            echo "ECR repository not found, removing from state"
            terraform state rm aws_ecr_repository.myapp || echo "Not in state"
          fi
          
          # Check and remove EKS cluster if it doesn't exist
          if ! aws eks describe-cluster --name my-eks-cluster &>/dev/null; then
            echo "EKS cluster not found, removing from state"
            terraform state rm 'module.eks.aws_eks_cluster.this[0]' || echo "Not in state"
            terraform state rm 'module.eks.aws_eks_node_group.this["app_nodes"]' || echo "Not in state"
          fi

      - name: Terraform Destroy
        run: terraform destroy -auto-approve